<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Blog on &gt; Hasith De Alwis</title>
    <link>http://localhost:1313/blog/</link>
    <description>Recent content in Blog on &gt; Hasith De Alwis</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 24 Aug 2025 10:30:00 -0400</lastBuildDate>
    <atom:link href="http://localhost:1313/blog/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Building Thread-Safe Event Systems in Go: A k6 waitForResponse Case Study</title>
      <link>http://localhost:1313/blog/thread-safe-event-systems-in-go/</link>
      <pubDate>Sun, 24 Aug 2025 10:30:00 -0400</pubDate>
      <guid>http://localhost:1313/blog/thread-safe-event-systems-in-go/</guid>
      <description>&lt;h1 id=&#34;building-thread-safe-event-systems-in-go-a-k6-waitforresponse-case-study&#34;&gt;Building Thread-Safe Event Systems in Go: A k6 waitForResponse Case Study&lt;/h1&gt;&#xA;&lt;p&gt;Browser automation tools need to wait for specific network responsesâ€”but building this in a concurrent system is trickier than it looks. When testing web applications, you often need to wait for an API call to complete before proceeding with the next action. Without proper synchronization, tests become flaky and unreliable. Recently, I &lt;a href=&#34;https://github.com/grafana/k6/pull/5002&#34;&gt;contributed&lt;/a&gt; the &lt;code&gt;waitForResponse&lt;/code&gt; API to k6&amp;rsquo;s browser module, architecting a thread-safe event system that handles hundreds of concurrent waiters without race conditions or resource leaks.&lt;/p&gt;</description>
    </item>
    <item>
      <title>How I merged 1k&#43; lines of Code into the Grafana Labs Ecosystem with AI</title>
      <link>http://localhost:1313/blog/1k-loc-grafana/</link>
      <pubDate>Wed, 20 Aug 2025 10:30:00 -0400</pubDate>
      <guid>http://localhost:1313/blog/1k-loc-grafana/</guid>
      <description>&lt;p&gt;Up until two months ago, I was very adverse against AI. I believed it lowered our ability to think critically, be creative, and to write good scalable code. I still believe this! But for better or for worse, we should learn how to use it effectively and in a manner such that we still LEARN.&lt;/p&gt;&#xA;&lt;p&gt;I strongly advise against people using AI for personal projects, but for work and contributing to large codebases, AI can be a helpful tool that allows you to optimize workflows and make your company more money.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Front-End best practices</title>
      <link>http://localhost:1313/blog/fe-best-practices/</link>
      <pubDate>Sat, 28 Dec 2024 10:30:00 -0400</pubDate>
      <guid>http://localhost:1313/blog/fe-best-practices/</guid>
      <description>&lt;p&gt;&lt;strong&gt;DISCLAIMER:&lt;/strong&gt; As predicted, I disagree with a lot of what I wrote here earlier ðŸ˜…. With that being said, I still want to keep it up since there is still some useful information, and it&amp;rsquo;s always fun to see how far you&amp;rsquo;ve come.&lt;/p&gt;&#xA;&lt;p&gt;Scalable front-end code is an expansive topic; of course, there are topics I can&amp;rsquo;t cover here, such as effective testing, development philosophies, monorepos, and much more. This article focuses on practical strategies for scaling front-end code in terms of architecture, maintainability, and technologies. My primary goal is to leave you with an idea of WHAT you should be researching and looking into, not necessarily explaining the nitty-gritty of all topics. This guide is meant to be framework agnostic, and my advice here should be transferable to any framework.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
